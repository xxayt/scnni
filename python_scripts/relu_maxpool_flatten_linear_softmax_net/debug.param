7767517
22 21
pnnx.Input               pnnx_input_0             0 1 x.1 #x.1=(1,3,4,4)f32
prim::Constant           pnnx_1                   0 1 19 value=-1
prim::Constant           pnnx_3                   0 1 9 value=2
prim::Constant           pnnx_4                   0 1 12 value=0
prim::Constant           pnnx_5                   0 1 14 value=1
nn.ReLU                  relu                     1 1 x.1 8 #x.1=(1,3,4,4)f32 #8=(1,3,4,4)f32
prim::Constant           pnnx_6                   0 1 36 value=2
prim::ListConstruct      pnnx_7                   2 1 9 36 10
prim::Constant           pnnx_8                   0 1 37 value=2
prim::Constant           pnnx_9                   0 1 38 value=2
prim::ListConstruct      pnnx_10                  2 1 37 38 11
prim::Constant           pnnx_11                  0 1 39 value=0
prim::ListConstruct      pnnx_12                  2 1 12 39 13
prim::Constant           pnnx_13                  0 1 40 value=1
prim::ListConstruct      pnnx_14                  2 1 14 40 15
prim::Constant           pnnx_16                  0 1 41 value=1
F.max_pool2d             F.max_pool2d_0           5 1 8 10 11 13 15 y.1 ceil_mode=False return_indices=False $input=8 $kernel_size=10 $stride=11 $padding=13 $dilation=15 #8=(1,3,4,4)f32 #y.1=(1,3,2,2)f32
torch.flatten            torch.flatten_2          3 1 y.1 41 19 input.1 $input=y.1 $start_dim=41 $end_dim=19 #y.1=(1,3,2,2)f32 #input.1=(1,12)f32
nn.Linear                linear                   1 1 input.1 23 bias=True in_features=12 out_features=3 @bias=(3)f32 @weight=(3,12)f32 #input.1=(1,12)f32 #23=(1,3)f32
prim::Constant           pnnx_18                  0 1 42 value=1
F.softmax                F.softmax_1              2 1 23 42 25 $input=23 $dim=42 #23=(1,3)f32 #25=(1,3)f32
pnnx.Output              pnnx_output_0            1 0 25 #25=(1,3)f32
